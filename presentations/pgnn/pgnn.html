<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Physics-guided Neural Networks (PGNN)</title>
<meta name="author" content="Anuj Karpatne^{*}, William Watkins^{\dagger}, Jordan Read^{\dagger}, & Vipin Kumar^{*}"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://ammunk.com/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://ammunk.com/reveal.js/dist/theme/serif.css" id="theme"/>

<link rel="stylesheet" href="https://ammunk.com/assets/img/utils/extra.css"/>
<link rel="stylesheet" href="https://ammunk.com/reveal.js/plugin/highlight/zenburn.css"/>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://ammunk.com/assets/js/mathjax-config.js" defer> </script>
<script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script> $(function(){$("#includedContent").load("./bibtex.html");}); </script>
<meta name="description" content="Assisting the Adversary to Improve GAN Training">
<script type="text/javascript" src=""></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<section id="sec-title-slide">
    <h1 class="title">Physics-guided Neural Networks (PGNN)</h1><h2 class="author">Anuj Karpatne<sup>*</sup>, William Watkins<sup>&dagger;</sup>, Jordan Read<sup>&dagger;</sup>, &amp; Vipin Kumar<sup>*</sup></h2>
    <h3 class="affiliation"><sup>&#42;</sup>Department of Computer Science, University of Minnesota, <sup>&#8224;</sup>United States Geological Survey</h3>
    <h2 class="presented">Presented By</h2>
    <h3 class="presented">Andreas Munk</h3>
    <h4 class="email"><a href="mailto:amunk@cs.ubc.ca">amunk@cs.ubc.ca</a></h4><h4 class="date">April 12, 2021</h4>
</section>

</section>
<section id="table-of-contents-section">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#/slide-org4f10035">Where is the physics in modern machine learning?</a></li>
<li><a href="#/slide-orgd6cfd84">Phisycs-guided Neural Networks (PGNN) [<a href="#/slide-karpatne2017physics">Karpatne et&nbsp;al., 2017</a>]</a></li>
<li><a href="#/slide-org5a138ed">Constructing Hybrid-Physics-Data models</a></li>
<li><a href="#/slide-org46bf5f3">Using physics-based loss functions</a></li>
<li><a href="#/slide-orge2672b5">Experiments</a></li>
<li><a href="#/slide-org472c3ee">Lake temperature modeling</a></li>
<li><a href="#/slide-org550ea5f">Physical inconsistency for lake temperature modeling</a>
<ul>
<li><a href="#/slide-org69652ea">Temperature-density relationship of water</a></li>
<li><a href="#/slide-org9f0a2af">Denisty-depth relationship</a></li>
</ul>
</li>
<li><a href="#/slide-org1de364c">Loss function for lake temperature modeling</a></li>
<li><a href="#/slide-orgeaf21b2">Results</a>
<ul>
<li><a href="#/slide-org399d32b">Models and their notation</a></li>
<li><a href="#/slide-org74b90c2">Root mean squared error (RMSE) and physical inconsistency</a></li>
<li><a href="#/slide-org0ef8e8a">Relation to training size (Lake Mille Lacs)</a></li>
<li><a href="#/slide-orgc50a7d8">Density-depth relationship</a></li>
</ul>
</li>
<li><a href="#/slide-orgf31236e">References</a></li>
</ul>
</div>
</div>
</section>
<div id="hiddenMathbox" style="display: none;">
<p>
\(
\newcommand{\ie}{i.e.}
\newcommand{\eg}{e.g.}
\newcommand{\etal}{\textit{et~al.}}
\newcommand{\wrt}{w.r.t.}
\newcommand{\bra}[1]{\langle #1 \mid}
\newcommand{\ket}[1]{\mid #1\rangle}
\newcommand{\braket}[2]{\langle #1 \mid #2 \rangle}
\newcommand{\bigbra}[1]{\big\langle #1 \big\mid}
\newcommand{\bigket}[1]{\big\mid #1 \big\rangle}
\newcommand{\bigbraket}[2]{\big\langle #1 \big\mid #2 \big\rangle}
\newcommand{\grad}{\boldsymbol{\nabla}}
\newcommand{\divop}{\grad\scap}
\newcommand{\pp}{\partial}
\newcommand{\ppsqr}{\partial^2}
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\trans}[1]{#1^\mr{T}}
\newcommand{\dm}{\,\mathrm{d}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\krondel}[1]{\delta_{#1}}
\newcommand{\limit}[2]{\mathop{\longrightarrow}_{#1 \rightarrow #2}}
\newcommand{\measure}{\mathbb{P}}
\newcommand{\scap}{\!\cdot\!}
\newcommand{\intd}[1]{\int\!\dm#1\: }
\newcommand{\ave}[1]{\left\langle #1 \right\rangle}
\newcommand{\br}[1]{\left\lbrack #1 \right\rbrack}
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\tub}[1]{\left\{#1\right\}}
\newcommand{\mr}[1]{\mathrm{#1}}
\newcommand{\evalat}[1]{\left.#1\right\vert}
\newcommand*{\given}{\mid}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}
\newcommand{\newterm}[1]{{\bf #1}}
\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\boldsymbol{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}
\def\eps{{\epsilon}}
\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}
\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}
\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}
\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}
\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}
\def\vzero{{\boldsymbol{0}}}
\def\vone{{\boldsymbol{1}}}
\def\vmu{{\boldsymbol{\mu}}}
\def\vtheta{{\boldsymbol{\theta}}}
\def\va{{\boldsymbol{a}}}
\def\vb{{\boldsymbol{b}}}
\def\vc{{\boldsymbol{c}}}
\def\vd{{\boldsymbol{d}}}
\def\ve{{\boldsymbol{e}}}
\def\vf{{\boldsymbol{f}}}
\def\vg{{\boldsymbol{g}}}
\def\vh{{\boldsymbol{h}}}
\def\vi{{\boldsymbol{i}}}
\def\vj{{\boldsymbol{j}}}
\def\vk{{\boldsymbol{k}}}
\def\vl{{\boldsymbol{l}}}
\def\vm{{\boldsymbol{m}}}
\def\vn{{\boldsymbol{n}}}
\def\vo{{\boldsymbol{o}}}
\def\vp{{\boldsymbol{p}}}
\def\vq{{\boldsymbol{q}}}
\def\vr{{\boldsymbol{r}}}
\def\vs{{\boldsymbol{s}}}
\def\vt{{\boldsymbol{t}}}
\def\vu{{\boldsymbol{u}}}
\def\vv{{\boldsymbol{v}}}
\def\vw{{\boldsymbol{w}}}
\def\vx{{\boldsymbol{x}}}
\def\vy{{\boldsymbol{y}}}
\def\vz{{\boldsymbol{z}}}
\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}
\def\mA{{\boldsymbol{A}}}
\def\mB{{\boldsymbol{B}}}
\def\mC{{\boldsymbol{C}}}
\def\mD{{\boldsymbol{D}}}
\def\mE{{\boldsymbol{E}}}
\def\mF{{\boldsymbol{F}}}
\def\mG{{\boldsymbol{G}}}
\def\mH{{\boldsymbol{H}}}
\def\mI{{\boldsymbol{I}}}
\def\mJ{{\boldsymbol{J}}}
\def\mK{{\boldsymbol{K}}}
\def\mL{{\boldsymbol{L}}}
\def\mM{{\boldsymbol{M}}}
\def\mN{{\boldsymbol{N}}}
\def\mO{{\boldsymbol{O}}}
\def\mP{{\boldsymbol{P}}}
\def\mQ{{\boldsymbol{Q}}}
\def\mR{{\boldsymbol{R}}}
\def\mS{{\boldsymbol{S}}}
\def\mT{{\boldsymbol{T}}}
\def\mU{{\boldsymbol{U}}}
\def\mV{{\boldsymbol{V}}}
\def\mW{{\boldsymbol{W}}}
\def\mX{{\boldsymbol{X}}}
\def\mY{{\boldsymbol{Y}}}
\def\mZ{{\boldsymbol{Z}}}
\def\mBeta{{\boldsymbol{\beta}}}
\def\mPhi{{\boldsymbol{\Phi}}}
\def\mLambda{{\boldsymbol{\Lambda}}}
\def\mSigma{{\boldsymbol{\Sigma}}}
\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}
\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}
\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}
\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}
\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}
\newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution
\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}
\newcommand{\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
\newcommand{\vxlat}{\vx_{\mr{lat}}}
\newcommand{\vxobs}{\vx_{\mr{obs}}}
\newcommand{\block}[1]{\underbrace{\begin{matrix}1 & \cdots & 1\end{matrix}}_{#1}}
\newcommand{\blockt}[1]{\begin{rcases} \begin{matrix} ~\\ ~\\ ~ \end{matrix} \end{rcases}{#1}}
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}
\)
</p>
</div>

<section>
<section id="slide-org4f10035">
<h2 id="org4f10035">Where is the physics in modern machine learning?</h2>
<ul>
<li>Neural networks (NN) are used for <i>black-box</i> modeling to solve regression and
classification problems</li>

<li>We cannot know if NNs even approximately captures underlying physical mechanics
<ul>
<li>Even if they produce small test scores (e.g. mean-square-error (MSE))</li>

</ul></li>

<li>This obfuscates the functional relationship between input (\(x\)) and output
(\(y\)) variables
<ul>
<li>Potentially impedes further scientific discoveries</li>
<li>Arguably, this &ldquo;issue&rdquo; is less relevant when modeling a statistical
relationship between \(x\) and \(y\) - i.e. \(p_{\theta}(y|x)\).
<ul>
<li><p>
Assume a &ldquo;true&rdquo; functional relationship between \(x\) and \(y\) with a noise
term,
\[y = f(x) + \epsilon\]
</p>

<p>
Any discrepancy between a learned function \(f_{\theta}\) and the true
function \(f\) may be summarized as uncertainty associated with
\(p_{\theta}(y|x)\)
</p></li>

</ul></li>

</ul></li>

<li>The perspective taken in this presentation is that we care about the
<i>functional</i> relation between \(x\) and \(y\)</li>

</ul>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-orgd6cfd84">
<h2 id="orgd6cfd84">Phisycs-guided Neural Networks (PGNN) [<a href="#karpatne2017physics">Karpatne et&nbsp;al., 2017</a>]</h2>
<ul>
<li>Combine neural networks with scientific knowledge of physics-based models</li>

<li>Introduce an additional loss term that penalizes &ldquo;flawed&rdquo; relationships
between input and output variables under the neural network model
<ul>
<li>The penalization is defined using known physical mechanics underlying the
problem at hand</li>
<li>These mechanics do not (necessarily) solve the problem, but encode certain
relationship between (subsets) of the variables involved</li>

</ul></li>

<li>This framework can effectively be viewed as constraining the training of the
neural networks</li>

</ul>

<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>
</section>
<section>


<div id="orgd34bf5c" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_difference.png" alt="pgnn_difference.png" width="1000" />
</p>
</div>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-org5a138ed">
<h2 id="org5a138ed">Constructing Hybrid-Physics-Data models</h2>
<ul>
<li>Consider input variables (observable data or &ldquo;drivers&rdquo;) \(D\in\gD\) and target
variable(s) \(Y\in\gY\)</li>

<li>Standard neural network model
<ul>
<li>\(f_{\mr{NN}}:\gD \rightarrow \gY\) with parameters \(\theta_{\mr{NN}}\)</li>

</ul></li>

<li>physics-based model
<ul>
<li>\(f_{\mr{PHY}}:\gD \rightarrow \gY\)</li>

</ul></li>

<li><i>Hybrid model</i>
<ul>
<li>\(f_{\mr{HPD}}:\gX=\gD\times\gY \rightarrow \gY\) with parameters
\(\theta_{\mr{HPD}}\)</li>
<li>Also takes outputs from the physics based model</li>

</ul></li>

<li>Define \(\hat{Y}_{\mr{NN}}=f_{\mr{NN}}(D)\) and
\(\hat{Y}_{\mr{HPD}}=f_{\mr{HPD}}(D,\hat{Y}_{\mr{NN}})\)</li>

</ul>


<div id="orgd4ee101" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_inputs.png" alt="pgnn_inputs.png" width="800" />
</p>
</div>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-org46bf5f3">
<h2 id="org46bf5f3">Using physics-based loss functions</h2>
<ul>
<li><p>
Consider the following minimization problem
</p>

<p>
\[
  \argmin_{\theta_{i}} \gL(\theta_{i})=\argmin_{\theta_{i}} \underbrace{\gL_{\mr{standard}}(\theta_{i})}_{\mr{"standard~loss"}} + \underbrace{\lambda R(\theta_{i})}_{\mr{regularization}} + \underbrace{\lambda_{\mr{PHY}}\gL_{\mr{PHY}}(\theta_{i})}_{\mr{Physical~Inconsistency}}, \quad i\in\tub{\mr{NN},\mr{HPD}},
  \]
</p>

<p>
with \(\lambda\) and \(\lambda_{\mr{PHY}}\) being hyperparameters
</p></li>

<li>The Physical Inconsistency &ldquo;measures constraint violations&rdquo;
<ul>
<li>Define equality and inequality constraints
\[
    \gG(Y,D) = 0 \quad \gH(Y, D) \leq 0
    \]</li>

<li>Both \(\gG\) and \(\gH\) are generic forms of physics-based (differentiable)
equations. Both forms captures a physics-based relationship between the
variable \(D\) and \(Y\).
<ul>
<li>For instance let \(D\) describe time and Y the position of an object. If we
know that the object moves with constant velocity (\(v\)) we can describe
it&rsquo;s position according to \(Y=f(D)=v\cdot D + Y_{0}\).</li>
<li>Use the knowledge of the velocity to relate \(Y\) and \(D\), e.g.
\(\gG(Y,D)=Y-(v\cdot D + Y_{0})\Rightarrow \gG(f(D),D)=0\)</li>

</ul></li>

</ul></li>

</ul>

<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>
</section>
<section>

<ul>
<li>Leading to the following loss term (framed as soft constraints)</li>

</ul>
<p>
\[
    \gL_{\mr{PHY}}(\theta_{i}) = \norm{\gG(f_{\mr{i}}(D),D)}^{2} + \mr{ReLU}(\gH(f_{\mr{i}}(D),D)) \quad i\in\tub{\mr{NN},\mr{HPD}}
  \]
</p>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-orge2672b5">
<h2 id="orge2672b5">Experiments</h2>
</section>
</section>
<section>
<section id="slide-org472c3ee">
<h2 id="org472c3ee">Lake temperature modeling</h2>
<ul>
<li>Predict lake temperatures \(Y\) using PGNN</li>

</ul>


<div id="org99b47ce" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_watersystem.png" alt="pgnn_watersystem.png" width="1000" />
</p>
</div>

<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>
</section>
<section>


<div id="orgc916a98" class="figure">
<p><img src="../../../assets/img/pgnn/figs/inputs.png" alt="inputs.png" width="1000" />
</p>
<p><span class="figure-number">Figure 4: </span>Input variables \(D\)</p>
</div>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-org550ea5f">
<h2 id="org550ea5f">Physical inconsistency for lake temperature modeling</h2>
<div class="outline-text-2" id="text-org550ea5f">
</div>
</section>
<section id="slide-org69652ea">
<h3 id="org69652ea">Temperature-density relationship of water</h3>
<div>
\begin{equation}\label{eq:rho}
\rho(T) = 1000\times \paren{1-\frac{(T+288.9414)(T-3.9863)^{2}}{508929.2(T+68.12963)}}
\end{equation}

</div>


<div id="org6ba899d" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_temp.png" alt="pgnn_temp.png" width="1000" />
</p>
</div>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
<section id="slide-org9f0a2af">
<h3 id="org9f0a2af">Denisty-depth relationship</h3>
<ul>
<li>Density is monotonically increasing with depth</li>

</ul>


<div id="org8046d38" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_density_depth.png" alt="pgnn_density_depth.png" width="600" />
</p>
<p><span class="figure-number">Figure 6: </span>Sketch of depth and density relationship</p>
</div>

<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>
</section>
<section>

<ul>
<li><p>
Consider two depths \(d_{1}\) and \(d_{2}\) at time \(t\), then the density as a
function of depth and time \(t\) must satisfy
</p>

<p>
\[
  \rho(d_{1},t) - \rho(d_{2},t) \leq 0, \quad d_{1} \leq d_{2}
  \]
</p></li>

<li>We can use the above requirement to construct the inequality constraint \(\gH\)
<ul>
<li>Consider the regular grid of \(n_{d}\) depth values and \(n_{t}\) time-steps</li>
<li>Consider \(\hat{\rho}(d_{k},t)=\rho(f_{i}(D))\), where \(\rho(\cdot)\) is from
\eqref{eq:rho}, the depth value and time value in \(D\) are equal \(d_{k}\) and \(t\)
respectively, and \(f\) is a function, e.g. \(f_{\mr{PHY}}\)</li>
<li>Define \(\Delta(k, t) = \hat{\rho}(d_{k}, t) - \hat{\rho}(d_{k+1}, t)\), with \(k\in\tub{1,\dots,n_{d}}\)</li>

</ul></li>
<li><p>
The physics regularized loss term then becomes
</p>

<p>
\[
  \gL_{\mr{PHY}}(\theta_{i}) = \frac{1}{n_{t}(n_{d}-1)}\sum_{t=1}^{n_{t}}\sum_{k}^{n_{d}-1}\mr{ReLU}(\Delta(k,t)),
  \]
</p>

<ul>
<li>Which we can differentiate with respect to \(\theta_{i}\)</li>

</ul></li>

</ul>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-org1de364c">
<h2 id="org1de364c">Loss function for lake temperature modeling</h2>
<div>
\begin{align*}
\gL_{\mr{stand}}(\theta_{i}) &= \frac{1}{n}\sum_{k=1}^{n}\paren{y_{i}-f_{i}(x_{i})}^{2}, \\
R(\theta_{i}) &= \lambda_{1}\norm{\theta_{i}}_{1} + \lambda_{2}\norm{\theta_{i}}_{2}, \\
\gL_{\mr{PHY}}(\theta_{i}) &= \frac{1}{n_{t}(n_{d}-1)}\sum_{t=1}^{n_{t}}\sum_{k}^{n_{d}-1}\mr{ReLU}(\Delta(k,t)),
\end{align*}

</div>

<ul>
<li>\(n\) is number of data points</li>
<li>\(n_{d}\) is the number of unique depth measurements (different depth values)</li>
<li>\(n_{t}\) is the number of unique time measurements (day of year)</li>
<li>\(\Delta(k,t)\) is part of the physical inconsistency loss, as defined earlier</li>

</ul>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>



</section>
</section>
<section>
<section id="slide-orgeaf21b2">
<h2 id="orgeaf21b2">Results</h2>
<div class="outline-text-2" id="text-orgeaf21b2">
</div>
</section>
<section id="slide-org399d32b">
<h3 id="org399d32b">Models and their notation</h3>
<ul>
<li>NN, SVM, LSBoost: to a standard neural network model trained without physical
knowledge, support vector machines, and least squared boosted regression tress</li>
<li>PHY: A state-of-the-art general lake model (simulator)</li>
<li>PGNN0: uses \(f_{\mr{PHY}}\) (i.e. takes simulated temperatures as additional
arguments), but does not use \(\gL_{\mr{PHY}}\)</li>
<li>PGNN: The proposed method</li>

<li>Define the <i>physical inconsistency</i> metric - a number representing the
fraction of times the density constraint is violated</li>

</ul>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>
</section>
<section id="slide-org74b90c2">
<h3 id="org74b90c2">Root mean squared error (RMSE) and physical inconsistency</h3>
<div class="container">
<div class="col">

<div id="org567b949" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_lake_mille.png" alt="pgnn_lake_mille.png" width="700" />
</p>
<p><span class="figure-number">Figure 7: </span>Lake Mille Lacs</p>
</div>
</div>

<div class="col">

<div id="org41e8db8" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_lake_mendota.png" alt="pgnn_lake_mendota.png" width="700" />
</p>
<p><span class="figure-number">Figure 8: </span>Lake Mendota</p>
</div>
</div>
<div class="col">
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
<section id="slide-org0ef8e8a">
<h3 id="org0ef8e8a">Relation to training size (Lake Mille Lacs)</h3>
<div class="container">
<div class="col">

<div id="orgf8678dc" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_size_mse.png" alt="pgnn_size_mse.png" width="700" />
</p>
</div>
</div>

<div class="col">

<div id="orge810412" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_consistency_size.png" alt="pgnn_consistency_size.png" width="700" />
</p>
</div>
</div>
<div class="col">
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
<section id="slide-orgc50a7d8">
<h3 id="orgc50a7d8">Density-depth relationship</h3>
<div class="container">
<div class="col">

<div id="org7c8916d" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_depth_dens_profile_mille.png" alt="pgnn_depth_dens_profile_mille.png" width="700" />
</p>
<p><span class="figure-number">Figure 11: </span>Lake Mille Lacs</p>
</div>
</div>

<div class="col">


<div id="org69f13b3" class="figure">
<p><img src="../../../assets/img/pgnn/figs/pgnn_depth_dens_mendota.png" alt="pgnn_depth_dens_mendota.png" width="700" />
</p>
<p><span class="figure-number">Figure 12: </span>Lake Mendota</p>
</div>
</div>
<div class="col">
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>

</section>
</section>
<section>
<section id="slide-orgf31236e">
<h2 id="orgf31236e">References</h2>
<div id="includedContent"></div>
<div class="slide-footer">Andreas Munk, <a href="mailto:andreas@ammunk.com">amunk@cs.ubc.ca</a>, <a href="https://ammunk.com">ammunk.com</a></div>
</section>
</section>
</div>
</div>
<script src="https://ammunk.com/reveal.js/dist/reveal.js"></script>
<script src="https://ammunk.com/reveal.js/plugin/highlight/highlight.js"></script>
<script src="https://ammunk.com/reveal.js/plugin/search/search.js"></script>
<script src="https://ammunk.com/reveal.js/plugin/zoom/zoom.js"></script>
<script src="https://ammunk.com/reveal.js/plugin/notes/notes.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: true,
center: true,
slideNumber: 't',
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: false,
hashOneBasedIndex: false,
pdfSeparateFragments: true,

overview: true,
width: 2000,
height: 1400,
margin: 0.00,
minScale: 0.30,
maxScale: 2.50,

transition: 'linear',
transitionSpeed: 'default',

// Plugins with reveal.js 4.x
plugins: [ RevealHighlight, RevealSearch, RevealZoom, RevealNotes ],

// Optional libraries used to extend reveal.js
dependencies: [
]

});
</script>
</body>
</html>
