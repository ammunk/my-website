
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="arjovsky2017wasserstein">Arjovsky et&nbsp;al., 2017</a>]
</td>
<td class="bibtexitem">
Arjovsky, M., Chintala, S., and Bottou, L. (2017).
 Wasserstein generative adversarial networks.
 In <em>International Conference on Machine Learning</em>, pages
  214--223.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="goodfellow2014generative">Goodfellow et&nbsp;al., 2014</a>]
</td>
<td class="bibtexitem">
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
  Ozair, S., Courville, A., and Bengio, Y. (2014).
 Generative adversarial nets.
 In <em>Advances in Neural Information Processing Systems 27</em>, pages
  2672--2680. Curran Associates, Inc.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="gulrajani2017improved">Gulrajani et&nbsp;al., 2017</a>]
</td>
<td class="bibtexitem">
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A.&nbsp;C.
  (2017).
 Improved training of wasserstein gans.
 In <em>Advances in Neural Information Processing Systems 30</em>, pages
  5767--5777. Curran Associates, Inc.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="karras2020analyzing">Karras et&nbsp;al., 2020</a>]
</td>
<td class="bibtexitem">
Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., and Aila, T.
  (2020).
 Analyzing and improving the image quality of stylegan.
 In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition</em>, pages 8110--8119.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mescheder2018which">Mescheder et&nbsp;al., 2018</a>]
</td>
<td class="bibtexitem">
Mescheder, L., Geiger, A., and Nowozin, S. (2018).
 Which training methods for gans do actually converge?
 In <em>International Conference on Machine Learning</em>, pages
  3481--3490. PMLR.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mescheder2017numerics">Mescheder et&nbsp;al., 2017</a>]
</td>
<td class="bibtexitem">
Mescheder, L., Nowozin, S., and Geiger, A. (2017).
 The numerics of gans.
 <em>Advances in Neural Information Processing Systems</em>,
  30:1825--1835.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="milgrom2002envelope">Milgrom and Segal, 2002</a>]
</td>
<td class="bibtexitem">
Milgrom, P. and Segal, I. (2002).
 Envelope theorems for arbitrary choice sets.
 <em>Econometrica</em>, 70(2):583--601.
[&nbsp;<a href="http://dx.doi.org/10.1111/1468-0262.00296">DOI</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="munk2020assisting">Munk et&nbsp;al., 2020</a>]
</td>
<td class="bibtexitem">
Munk, A., Harvey, W., and Wood, F. (2020).
 Assisting the adversary to improve gan training.
 <em>arXiv:2010.01274 [cs, stat]</em>.
[&nbsp;<a href="http://arxiv.org/abs/2010.01274">arXiv</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="nagarajan2017gradient">Nagarajan and Kolter, 2017</a>]
</td>
<td class="bibtexitem">
Nagarajan, V. and Kolter, J.&nbsp;Z. (2017).
 Gradient descent gan optimization is locally stable.
 <em>Advances in Neural Information Processing Systems</em>,
  30:5585--5595.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="zhou2019hype">Zhou et&nbsp;al., 2019</a>]
</td>
<td class="bibtexitem">
Zhou, S., Gordon, M., Krishna, R., Narcomey, A., Fei-Fei, L.&nbsp;F., and
  Bernstein, M. (2019).
 Hype: A benchmark for human eye perceptual evaluation of generative
  models.
 In <em>Advances in Neural Information Processing Systems</em>, pages
  3449--3461.

</td>
</tr>
</table>